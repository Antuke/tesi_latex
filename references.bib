% FairFace Dataset
@article{fairface,
	author       = {Kimmo K{\"{a}}rkk{\"{a}}inen and
	Jungseock Joo},
	title        = {FairFace: Face Attribute Dataset for Balanced Race, Gender, and Age},
	journal      = {CoRR},
	volume       = {abs/1908.04913},
	year         = {2019},
	url          = {http://arxiv.org/abs/1908.04913},
	eprinttype    = {arXiv},
	eprint       = {1908.04913},
	timestamp    = {Mon, 19 Aug 2019 13:21:03 +0200},
	biburl       = {https://dblp.org/rec/journals/corr/abs-1908-04913.bib},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}

% LAGENDA Dataset
@article{mivolo2023,
	Author = {Maksim Kuprashevich and Irina Tolstykh},
	Title = {MiVOLO: Multi-input Transformer for Age and Gender Estimation},
	Year = {2023},
	Eprint = {arXiv:2307.04616},
}

% LAGENDA Dataset
@article{mivolo2024,
	Author = {Maksim Kuprashevich and Grigorii Alekseenko and Irina Tolstykh},
	Title = {Beyond Specialization: Assessing the Capabilities of MLLMs in Age and Gender Estimation},
	Year = {2024},
	Eprint = {arXiv:2403.02302},
}

% VGGFace2 Dataset
@misc{vggface2,
	title={VGGFace2: A dataset for recognising faces across pose and age}, 
	author={Qiong Cao and Li Shen and Weidi Xie and Omkar M. Parkhi and Andrew Zisserman},
	year={2018},
	eprint={1710.08092},
	archivePrefix={arXiv},
	primaryClass={cs.CV},
	url={https://arxiv.org/abs/1710.08092}, 
}


% IMDB-clean Dataset
@article{imdb-clean,
	title={FP-Age: Leveraging Face Parsing Attention for Facial Age Estimation in the Wild}, 
	author={Yiming Lin and Jie Shen and Yujiang Wang and Maja Pantic},
	year={2021},
	eprint={2106.11145},
	journal={arXiv},
	primaryClass={cs.CV}
}


% UtkFace Dataset
@misc{utkface,
	title={Age Progression/Regression by Conditional Adversarial Autoencoder}, 
	author={Zhifei Zhang and Yang Song and Hairong Qi},
	year={2017},
	eprint={1702.08423},
	archivePrefix={arXiv},
	primaryClass={cs.CV},
	url={https://arxiv.org/abs/1702.08423}, 
}


% Raf-db Dataset
@article{raf-db,
	title={Reliable Crowdsourcing and Deep Locality-Preserving Learning for Expression Recognition in the Wild},
	author={Shan Li and Weihong Deng and Junping Du},
	journal={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	year={2017},
	pages={2584-2593},
	url={https://api.semanticscholar.org/CorpusID:11413183}
}


% Celeba
@inproceedings{celeba1,
	title={TediGAN: Text-Guided Diverse Face Image Generation and Manipulation},
	author={Xia, Weihao and Yang, Yujiu and Xue, Jing-Hao and Wu, Baoyuan},
	booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	year={2021}
}

% Celeba
@article{celeba2,
	title={Towards Open-World Text-Guided Face Image Generation and Manipulation},
	author={Xia, Weihao and Yang, Yujiu and Xue, Jing-Hao and Wu, Baoyuan},
	journal={arxiv preprint arxiv: 2104.08910},
	year={2021}
}




% LoRa
@misc{lora,
	title={LoRA: Low-Rank Adaptation of Large Language Models}, 
	author={Edward J. Hu and Yelong Shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen},
	year={2021},
	eprint={2106.09685},
	archivePrefix={arXiv},
	primaryClass={cs.CL},
	url={https://arxiv.org/abs/2106.09685}, 
}


% MoE LoRa
@misc{moelora,
	title={MoELoRA: Contrastive Learning Guided Mixture of Experts on Parameter-Efficient Fine-Tuning for Large Language Models}, 
	author={Tongxu Luo and Jiahe Lei and Fangyu Lei and Weihao Liu and Shizhu He and Jun Zhao and Kang Liu},
	year={2024},
	eprint={2402.12851},
	archivePrefix={arXiv},
	primaryClass={cs.CL},
	url={https://arxiv.org/abs/2402.12851}, 
}

% MTLoRa
@misc{agiza2024mtloralowrankadaptationapproach,
	title={MTLoRA: A Low-Rank Adaptation Approach for Efficient Multi-Task Learning}, 
	author={Ahmed Agiza and Marina Neseem and Sherief Reda},
	year={2024},
	eprint={2403.20320},
	archivePrefix={arXiv},
	primaryClass={cs.CV},
	url={https://arxiv.org/abs/2403.20320}, 
}

% LoRa for image-classification
@INPROCEEDINGS{lora_vit2,
	author={Tiwary, Anupam and Sarkar, Shek Diya and Singh, Aditya Pratap and Agarwal, Pankaj Kumar and Burman, Subham and Poddar, Rishab},
	booktitle={2025 8th International Conference on Electronics, Materials Engineering & Nano-Technology (IEMENTech)}, 
	title={Fine-Tuning Vision Transformer Using LoRA for Image Classification}, 
	year={2025},
	volume={},
	number={},
	pages={1-4},
	keywords={Training;Adaptation models;Computer vision;Accuracy;Translation;Computational modeling;Dogs;Transformers;Real-time systems;Image classification;Vision Transformers;Food101;Cats vs Dogs LoRA;hugging face;PEFT},
	doi={10.1109/IEMENTech65115.2025.10959407}}

% LoRa for image-classification
@Article{lora_vit1,
	AUTHOR = {Hong, Zhenchen and Xiong, Jingwei and Yang, Han and Mo, Yu K.},
	TITLE = {Lightweight Low-Rank Adaptation Vision Transformer Framework for Cervical Cancer Detection and Cervix Type Classification},
	JOURNAL = {Bioengineering},
	VOLUME = {11},
	YEAR = {2024},
	NUMBER = {5},
	ARTICLE-NUMBER = {468},
	URL = {https://www.mdpi.com/2306-5354/11/5/468},
	PubMedID = {38790335},
	ISSN = {2306-5354},
	DOI = {10.3390/bioengineering11050468}
}

%Dora
@misc{Dora,
	title={DoRA: Weight-Decomposed Low-Rank Adaptation}, 
	author={Shih-Yang Liu and Chien-Yi Wang and Hongxu Yin and Pavlo Molchanov and Yu-Chiang Frank Wang and Kwang-Ting Cheng and Min-Hung Chen},
	year={2024},
	eprint={2402.09353},
	archivePrefix={arXiv},
	primaryClass={cs.CL},
	url={https://arxiv.org/abs/2402.09353}, 
}


% PEFT review
@misc{peft_review,
	title={Parameter-Efficient Fine-Tuning Methods for Pretrained Language Models: A Critical Review and Assessment}, 
	author={Lingling Xu and Haoran Xie and Si-Zhao Joe Qin and Xiaohui Tao and Fu Lee Wang},
	year={2023},
	eprint={2312.12148},
	archivePrefix={arXiv},
	primaryClass={cs.CL},
	url={https://arxiv.org/abs/2312.12148}, 
}


% LoRa teoria
@misc{lora_theory,
	title={LoRA Training Provably Converges to a Low-Rank Global Minimum or It Fails Loudly (But it Probably Won't Fail)}, 
	author={Junsu Kim and Jaeyeon Kim and Ernest K. Ryu},
	year={2025},
	eprint={2502.09376},
	archivePrefix={arXiv},
	primaryClass={cs.LG},
	url={https://arxiv.org/abs/2502.09376}, 
}

% LoRA+
@misc{lora_plus,
	title={LoRA+: Efficient Low Rank Adaptation of Large Models}, 
	author={Soufiane Hayou and Nikhil Ghosh and Bin Yu},
	year={2024},
	eprint={2402.12354},
	archivePrefix={arXiv},
	primaryClass={cs.LG},
	url={https://arxiv.org/abs/2402.12354}, 
}


@misc{lora_img,
	title={What is LoRA (low-rank adaption)?},
	author={Joshua Noble},
	url={https://www.ibm.com/think/topics/lora}
}


% swin
@misc{liu2021swintransformerhierarchicalvision,
	title={Swin Transformer: Hierarchical Vision Transformer using Shifted Windows}, 
	author={Ze Liu and Yutong Lin and Yue Cao and Han Hu and Yixuan Wei and Zheng Zhang and Stephen Lin and Baining Guo},
	year={2021},
	eprint={2103.14030},
	archivePrefix={arXiv},
	primaryClass={cs.CV},
	url={https://arxiv.org/abs/2103.14030}, 
}

@article{lora_in_vits, title={Parameter-Efficient Model Adaptation for Vision Transformers}, volume={37}, url={https://ojs.aaai.org/index.php/AAAI/article/view/25160}, DOI={10.1609/aaai.v37i1.25160}, abstractNote={In computer vision, it has achieved great transfer learning performance via adapting large-scale pretrained vision models (e.g., vision transformers) to downstream tasks. Common approaches for model adaptation either update all model parameters or leverage linear probes. In this paper, we aim to study parameter-efficient model adaptation strategies for vision transformers on the image classification task. We formulate efficient model adaptation as a subspace training problem and perform a comprehensive benchmarking over different efficient adaptation methods. We conduct an empirical study on each efficient model adaptation method focusing on its performance alongside parameter cost. Furthermore, we propose a parameter-efficient model adaptation framework, which first selects submodules by measuring local intrinsic dimensions and then projects them into subspace for further decomposition via a novel Kronecker Adaptation method. We analyze and compare our method with a diverse set of baseline model adaptation methods (including state-of-the-art methods for pretrained language models). Our method performs the best in terms of the tradeoff between accuracy and parameter efficiency across 20 datasets under the few-shot setting and 7 image classification datasets under the full-shot setting.}, number={1}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={He, Xuehai and Li, Chunyuan and Zhang, Pengchuan and Yang, Jianwei and Wang, Xin Eric}, year={2023}, month={Jun.}, pages={817-825} }

@misc{lora_learnforgets,
	title={LoRA Learns Less and Forgets Less}, 
	author={Dan Biderman and Jacob Portes and Jose Javier Gonzalez Ortiz and Mansheej Paul and Philip Greengard and Connor Jennings and Daniel King and Sam Havens and Vitaliy Chiley and Jonathan Frankle and Cody Blakeney and John P. Cunningham},
	year={2024},
	eprint={2405.09673},
	archivePrefix={arXiv},
	primaryClass={cs.LG},
	url={https://arxiv.org/abs/2405.09673}, 
}

@misc{shuttleworth2025loravsfinetuningillusion,
	title={LoRA vs Full Fine-tuning: An Illusion of Equivalence}, 
	author={Reece Shuttleworth and Jacob Andreas and Antonio Torralba and Pratyusha Sharma},
	year={2025},
	eprint={2410.21228},
	archivePrefix={arXiv},
	primaryClass={cs.LG},
	url={https://arxiv.org/abs/2410.21228}, 
}


% transformers
@misc{transformers,
	title={Attention Is All You Need}, 
	author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
	year={2023},
	eprint={1706.03762},
	archivePrefix={arXiv},
	primaryClass={cs.CL},
	url={https://arxiv.org/abs/1706.03762}, 
}

%ViT
@misc{vit,
	title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale}, 
	author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
	year={2021},
	eprint={2010.11929},
	archivePrefix={arXiv},
	primaryClass={cs.CV},
	url={https://arxiv.org/abs/2010.11929}, 
}

%Slora
@article{slora,
	title={S-LoRA: Serving Thousands of Concurrent LoRA Adapters},
	author={Sheng, Ying and Cao, Shiyi and Li, Dacheng and Hooper, Coleman and Lee, Nicholas and Yang, Shuo and Chou, Christopher and Zhu, Banghua and Zheng, Lianmin and Keutzer, Kurt and Gonzalez, Joseph E. and Stoica, Ion},
	journal={arXiv preprint arXiv:2311.03285},
	year={2023}
}

%mlora
@misc{mlora,
	title={mLoRA: Fine-Tuning LoRA Adapters via Highly-Efficient Pipeline Parallelism in Multiple GPUs}, 
	author={Zhengmao Ye and Dengchun Li and Zetao Hu and Tingfeng Lan and Jian Sha and Sicong Zhang and Lei Duan and Jie Zuo and Hui Lu and Yuanchun Zhou and Mingjie Tang},
	year={2024},
	eprint={2312.02515},
	archivePrefix={arXiv},
	primaryClass={cs.LG},
	url={https://arxiv.org/abs/2312.02515}, 
}

@misc{BLoRA,
	author       = {Ali Sabet},
	title        = {{BLoRA}: Maximize GPU util by routing inference through multiple LoRAs in same batch.},
	year={2024},
	howpublished = {GitHub repository},
	url          = {https://github.com/sabetAI/BLoRA},
}

%qlora
@misc{qlora,
	title={QLoRA: Efficient Finetuning of Quantized LLMs}, 
	author={Tim Dettmers and Artidoro Pagnoni and Ari Holtzman and Luke Zettlemoyer},
	year={2023},
	eprint={2305.14314},
	archivePrefix={arXiv},
	primaryClass={cs.LG},
	url={https://arxiv.org/abs/2305.14314}, 
}

%Lorahub
@misc{huang2024lorahubefficientcrosstaskgeneralization,
	title={LoraHub: Efficient Cross-Task Generalization via Dynamic LoRA Composition}, 
	author={Chengsong Huang and Qian Liu and Bill Yuchen Lin and Tianyu Pang and Chao Du and Min Lin},
	year={2024},
	eprint={2307.13269},
	archivePrefix={arXiv},
	primaryClass={cs.CL},
	url={https://arxiv.org/abs/2307.13269}, 
}